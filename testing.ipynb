{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpickle n_words, translation_len, votes, n_translations from data folder\n",
    "with open('data/n_words.pkl', 'rb') as f:\n",
    "    n_words = pickle.load(f)\n",
    "\n",
    "with open('data/translation_len.pkl', 'rb') as f:\n",
    "    translation_len = pickle.load(f)\n",
    "\n",
    "with open('data/votes.pkl', 'rb') as f:\n",
    "    votes = pickle.load(f)\n",
    "    \n",
    "with open('data/n_translations.pkl', 'rb') as f:\n",
    "    n_translations = pickle.load(f)\n",
    "\n",
    "with open('data/true_likes.pkl', 'rb') as f:\n",
    "    true_likes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_scaling_numpy(data, new_min=1, new_max=10):\n",
    "    if data.size == 0:\n",
    "        return data\n",
    "    original_min = np.min(data)\n",
    "    original_max = np.max(data)\n",
    "\n",
    "    if original_min == original_max or new_min == new_max:\n",
    "        return data\n",
    "    scaled_data = ((data - original_min) / (original_max - original_min)) * (new_max - new_min) + new_min\n",
    "    \n",
    "    return scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_entropy(prob_distribution, temperature):\n",
    "    temperature = max(1e-3, temperature)\n",
    "    scaled_probs = np.power(prob_distribution, 1 / temperature)\n",
    "    adjusted_distribution = scaled_probs / np.sum(scaled_probs)\n",
    "\n",
    "    return adjusted_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_ranked = np.argsort(true_likes)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  32,  230, 2687, 1649,  566,  667,  576,  965,  824,  758,  867,\n",
       "        896, 1200,  656,  825,  629,  742, 1810, 3247, 2632, 1509, 2272,\n",
       "       3447, 1696, 2255, 1408, 1519, 1475, 2079, 1926])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  107,   692,  2151,  2512,  1361,  1651,  1409,  3070,  2019,\n",
       "        1859,  2206,  2842,  3254,  2736,  3221,  2289,  2212,  3290,\n",
       "        6156, 10378, 10622,  6171,  6928,  6097,  7073,  5222,  6818,\n",
       "        7259,  8409,  9960])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert votes to numpy array of sums of lists\n",
    "votes = np.array([sum(v) for v in votes.values()])\n",
    "votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlovotvirModel:\n",
    "\n",
    "    def __init__(self, n_words, translation_len, votes, n_translations, a, b, t) -> None:\n",
    "        # epoch states \n",
    "        self.n_words = n_words\n",
    "        self.translation_len = translation_len\n",
    "        self.votes = votes\n",
    "        self.n_translations = n_translations\n",
    "\n",
    "        # cumulative words\n",
    "        self.cum_words = np.cumsum(n_words)\n",
    "\n",
    "        # hyperparameters\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.t = t\n",
    "\n",
    "        self.words = dict()\n",
    "        for i in range(sum(n_words)):\n",
    "            self.words[i] = [[], []] # [[likes], [lengths]]\n",
    "\n",
    "    \n",
    "    def like_prob(self, \n",
    "                  lengths, \n",
    "                  likes):\n",
    "        probs = lengths ** self.a + likes ** self.b\n",
    "        return probs / probs.sum()\n",
    "    \n",
    "    def run_epoch(self, epoch):\n",
    "        # n_words = self.n_words[epoch]\n",
    "        n_translations = self.n_translations[epoch]\n",
    "        votes = self.votes[epoch]\n",
    "        cum_words = self.cum_words[epoch]\n",
    "\n",
    "        # distribute n_translation into an array of length cum_words\n",
    "        translation_num = np.random.multinomial(n_translations, np.ones(cum_words)/cum_words)\n",
    "\n",
    "        # get the indices of non-zero elements in translation_num\n",
    "        non_zero_indices = np.nonzero(translation_num)[0]\n",
    "\n",
    "        # update the words list only for non-zero indices\n",
    "        for i in non_zero_indices:\n",
    "            n = translation_num[i]\n",
    "            self.words[i][0] += [0] * n # initialize likes to 0\n",
    "            self.words[i][1] += np.random.choice(self.translation_len, n).tolist() # initialize lengths to random values\n",
    "\n",
    "        # randomly choose votes words with replacement where indices are <= cum_words such that words[i][1] is not empty\n",
    "        # indices of words where words[i][1] is not empty\n",
    "        indices = np.array([i for i in range(cum_words) if len(self.words[i][0]) > 0])\n",
    "        cum_likes = np.array([sum(self.words[i][1]) for i in indices])\n",
    "        indices = np.random.choice(indices, \n",
    "                                   size=votes, \n",
    "                                   p=adjust_entropy(cum_likes / cum_likes.sum(), temperature=self.t), replace=True)\n",
    "        \n",
    "        for _ in indices:\n",
    "            # get the word\n",
    "            likes = min_max_scaling_numpy(np.array(self.words[_][0]))\n",
    "            lengths = min_max_scaling_numpy(np.array(self.words[_][1]))\n",
    "\n",
    "            # get the probability of liking each translation\n",
    "            probs = self.like_prob(lengths, likes)\n",
    "\n",
    "            # choose a translation\n",
    "            translation = np.random.choice(likes, p=probs)\n",
    "\n",
    "            # update the number of likes for the translation\n",
    "            self.words[_][0][likes.tolist().index(translation)] += 1\n",
    "\n",
    "\n",
    "            \n",
    "    def run(self):\n",
    "        n_epochs = len(self.n_words)\n",
    "        for epoch in range(n_epochs):\n",
    "            self.run_epoch(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_len.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(a, b, t):\n",
    "    model = SlovotvirModel(n_words, translation_len, votes, n_translations, a, b, t)\n",
    "    model.run()\n",
    "    # combine all likes list from the model\n",
    "    likes = []\n",
    "    for i in range(len(model.words)):\n",
    "        likes += model.words[i][0]\n",
    "\n",
    "    likes = np.array(likes)\n",
    "    likes_ranked = np.argsort(likes)[::-1]\n",
    "    return likes[likes_ranked]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "likes_model = run_model(0, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130394"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(true_likes.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129974"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(sum(votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129974"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(likes_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9967789928984463"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(likes_model) / sum(true_likes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "for _ in range(10):\n",
    "        likes_model = run_model(4.8, 5.6, 0.36)\n",
    "        plt.plot(range(len(likes_model)), \n",
    "                likes_model, \n",
    "                color='red', \n",
    "                linewidth=1, alpha=0.3, label = 'posterior estimation')\n",
    "for _ in range(10):\n",
    "        likes_model = run_model(10, 0, 0.5)\n",
    "        plt.plot(range(len(likes_model)), \n",
    "                likes_model, \n",
    "                color='blue', \n",
    "                linewidth=1, alpha=0.3, label='length bias')\n",
    "for _ in range(10):\n",
    "        likes_model = run_model(10, 0, 0.5)\n",
    "        plt.plot(range(len(likes_model)), \n",
    "                likes_model, \n",
    "                color='green', \n",
    "                linewidth=1, alpha=0.3, label='frequency bias')\n",
    "plt.plot(range(len(true_likes)), \n",
    "        true_likes[true_ranked], \n",
    "        linewidth=2, color='black')\n",
    "ax.set_xlabel('Rank (log scale)')\n",
    "ax.set_ylabel('Number of likes')\n",
    "ax.set_yscale('log')\n",
    "ax.yaxis.set_major_formatter(mticker.ScalarFormatter())\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "by_label = dict(zip(labels, handles))\n",
    "plt.legend(by_label.values(), by_label.keys())\n",
    "ax.set_xscale('log')\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=0.8)\n",
    "ax.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\n",
    "ax.minorticks_on()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
